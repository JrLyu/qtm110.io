
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>Module 12 Multiple Testing, Reporting Bias, and Misinterpreting Outliers Â· GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-katex/katex.min.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="Module13.html" />
    
    
    <link rel="prev" href="Module11.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="./">
            
                <a href="./">
            
                    
                    QTM 110 Intro to Scientific Methods
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.1.1" data-path="Module2.html">
            
                <a href="Module2.html">
            
                    
                    Module 2 Correlations and Causation
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.2" data-path="Module3.html">
            
                <a href="Module3.html">
            
                    
                    Module 3 Making Comparisons
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.3" data-path="Module4.html">
            
                <a href="Module4.html">
            
                    
                    Module 4 A Useful Equation
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.4" data-path="Module5.html">
            
                <a href="Module5.html">
            
                    
                    Module 5 Biases and Noises
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.5" data-path="Module6.html">
            
                <a href="Module6.html">
            
                    
                    Module 6 Experiments
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.6" data-path="Module7.html">
            
                <a href="Module7.html">
            
                    
                    Module 7 Regression
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.7" data-path="Module8.html">
            
                <a href="Module8.html">
            
                    
                    Module 8 Difference-in-Differences
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.8" data-path="Module9.html">
            
                <a href="Module9.html">
            
                    
                    Module 9 Regression Discontinuity Design
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.9" data-path="Module10.html">
            
                <a href="Module10.html">
            
                    
                    Module 10 Non-Compliance and Instruments
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.10" data-path="Module11.html">
            
                <a href="Module11.html">
            
                    
                    Module 11 Bayesian Inference and Base Rates
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.1.11" data-path="Module12.html">
            
                <a href="Module12.html">
            
                    
                    Module 12 Multiple Testing, Reporting Bias, and Misinterpreting Outliers
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.12" data-path="Module13.html">
            
                <a href="Module13.html">
            
                    
                    Module 13 Reversion to the Mean
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.13" data-path="Module14.html">
            
                <a href="Module14.html">
            
                    
                    Module 14 Adaptation
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.14" data-path="Module15.html">
            
                <a href="Module15.html">
            
                    
                    Module 15 Prediction
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="." >Module 12 Multiple Testing, Reporting Bias, and Misinterpreting Outliers</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="multiple-testing-reporting-bias-and-misinterpreting-outliers">Multiple Testing, Reporting Bias, and Misinterpreting Outliers</h1>
<h2 id="introduction-to-multiple-testing">Introduction to Multiple Testing</h2>
<ul>
<li>The General Problem<ul>
<li>Statistical testing and p-values are great ides.</li>
<li>When we find patterns in the world, we want to know if they reflect genuine phenomena or if they could have easily been produced by random chance.</li>
<li>For any given statistical result, these tools can help us figure out if the result is easily explained by chance or not.</li>
<li>HOWEVER, we face the file drawer problem: the public don&apos;t get to see all statistical tests that were conducted or could have been conducted. We only see the ones that were published (usually are those &quot;statistically significant&quot; ones).</li>
<li>Testing multiple hypotheses + selectively reporting only the significant results = dangerous combination.</li>
</ul>
</li>
<li>A General Phenomenon<ul>
<li>Once we appreciate the problem of multiple testing and selective reporting, we start to see it everywhere.</li>
<li>We might even wonder if we know anything</li>
</ul>
</li>
</ul>
<h2 id="multiple-testing-in-research-practice">Multiple Testing in Research Practice</h2>
<ul>
<li><strong>p-Hacking</strong>: An analyst knows that their result is much more interesting, exciting, and publishable if the result is statistically significant. They play around with their sample, their specification, etc. until they get a significant result, and they only report that one. </li>
<li><strong>p-Screening</strong>: Honest researchers formulate hypotheses and conduct their tests. However, the statistically significant results are more likely to be written up, published, and publicized because those results are more interesting. </li>
<li>In both cases, we can end up with lots of false positives and overestimates. </li>
<li>Giving ourselves too many chances: <ul>
<li>If we give ourselves a lot of chances to reject the null, the chances are pretty good that we will get at least one p&lt;0.05.</li>
<li>Ways to give ourselves too many changes? <ul>
<li>Asking Different Questions<ul>
<li>If we ask a lot of different questions and conduct a hypothesis test for each one, the chances are very good at least one will look significant. </li>
</ul>
</li>
<li>Trying Different Methods<ul>
<li>When we conduct the first independent data analysis, researches have to make various choices (which method to use, which variables to include, etc.). These choices can be collectively called the <strong>researcher degrees of freedom</strong>. Or more colloquially, &quot;wiggle room&quot;.</li>
<li>Sometimes, researchers can feel tempted to <strong>peak and tweak</strong>. This need not be malicious or deliberate. We are all human and feel pressure and want to be proven right. It doesn&apos;t make us bad people, but as a scientist/analyst, we need to be on guard against this temptation. </li>
</ul>
</li>
<li>Testing Subgroups<ul>
<li>Instead of increasing our chances by trying different analytical methods or questions, we could just look at the same questions and methods indifferent <strong>subgroups</strong>. </li>
</ul>
</li>
<li>Quietly Conducting Multiple Studies (screening)<ul>
<li><strong>Reporting/Publication Bias</strong>: scientific journals, and, consequently, the broader press, have a strong preference for statistically significant results. The practice of only publishing and reporting statistically significant results is called <strong>publication bias</strong> or <strong>reporting bias</strong>.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>How do we know p-hacking and p-screening is a problem? <ul>
<li>We know how p-values are defined, so we have an expectation about how likely any value of p would be.<ul>
<li>Specifically, p-values are uniformly distributed under the null. </li>
<li>This just means, assuming no bias and the null is true (i.e. there is no effect), we expect to see p-values of 0.01, 0.02, 0.03, etc. with equal probability. <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>&#x27F6;</mo></mrow><annotation encoding="application/x-tex">\longrightarrow</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.511em;"></span><span class="strut bottom" style="height:0.522em;vertical-align:-0.011em;"></span><span class="base textstyle uncramped"><span class="mrel">&#x27F6;</span></span></span></span> 20% chance of observing a p-value <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>&#x2264;</mo></mrow><annotation encoding="application/x-tex">\leq</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.63597em;"></span><span class="strut bottom" style="height:0.7719400000000001em;vertical-align:-0.13597em;"></span><span class="base textstyle uncramped"><span class="mrel">&#x2264;</span></span></span></span> 0.2, 5% chance of observing a p-value <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>&#x2264;</mo></mrow><annotation encoding="application/x-tex">\leq</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.63597em;"></span><span class="strut bottom" style="height:0.7719400000000001em;vertical-align:-0.13597em;"></span><span class="base textstyle uncramped"><span class="mrel">&#x2264;</span></span></span></span> 0.05, and 99% chance of observing a p-value <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>&#x2264;</mo></mrow><annotation encoding="application/x-tex">\leq</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.63597em;"></span><span class="strut bottom" style="height:0.7719400000000001em;vertical-align:-0.13597em;"></span><span class="base textstyle uncramped"><span class="mrel">&#x2264;</span></span></span></span> 0.99.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="potential-solutions-to-p-hacing-and-p-screening">Potential Solutions to p-Hacing and p-Screening</h2>
<ul>
<li>The general problem of multiple testing and selective reporting in quantitative studies is very hard to fix. But here are some potential solutions:<ul>
<li><strong>Pre-registration</strong>:<ul>
<li>Researchers could pre-register their studies: say exactly what they plan to test for and how; report the results of their pre-registered tests regardless of the result.</li>
<li>Researchers are using a 5% significance threshold, which means that under the null, we would expect 5% to be significant by chance.<ul>
<li>That means the proportion of things being tested are actually effective is closer to 3%. </li>
<li>Even conditional on a successful trial, the chances of genuine effectiveness are about 3 in 8.</li>
</ul>
</li>
<li>For pre-registration to be an effective solution, it has to be done well: we cannot just let researchers pre-register 100 tests and report the favorable ones. There&apos;s a lot of that going on now in the social sciences. </li>
</ul>
</li>
<li><strong>Replication</strong>: <ul>
<li>One way to know if an estimated effect is genuine is to replicate it. <ul>
<li>It is not fool proof. Suppose we use a 5% significance threshold, there is still a 0.05*0.05=0.025 chance of two significant estimates by chance.</li>
<li>And failure to reject the null is not proof of the null: so, we might wrongly reject real effects by conducting low-power replications.</li>
<li>Ideally, we would get lots and lots of data and replicate on very large samples.</li>
</ul>
</li>
<li>Sometimes, replication is feasible, and sometimes it is not. </li>
</ul>
</li>
<li><strong>Change our Significance Threshold</strong>: <ul>
<li>Maybe we can solve the problem of multiple testing and false-positive results by using lower significance thresholds of p-values. <ul>
<li>Maybe the convention of 5% got us into some trouble.</li>
<li>If we have enough statistical power, it would be great to use lower significance. </li>
</ul>
</li>
<li>However, any bright line will cause the same problems that we&apos;ve been discussing, and lower p-values could actually make the problem worse in some respects. <ul>
<li>Lower significance thresholds will likely lead us to overestimate actual treatment effects even more than we do today.</li>
</ul>
</li>
<li>Therefore, it is better to not obsess over significance thresholds at all, rather than changing them. </li>
</ul>
</li>
<li><strong>Don&apos;t Obsess over Statistical Significance</strong>: <ul>
<li>p=0.05 is just an arbitrary threshold.<ul>
<li>Substantively important effect may be statistically insignificant, and </li>
<li>Statistically significant result may be substantively unimportant.</li>
</ul>
</li>
<li>We could use an entirely different paradigm for reporting results, like <strong>estimation paradigm</strong> or <strong>Bayesian inference</strong> that emphasize estimating effect sizes and uncertainty over p-values.<ul>
<li>Require paradigm shift (hard, unlikely)</li>
<li>Sometimes we do have to make a yes/no decision about an effect.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Multiple Testing Corrections</strong><ul>
<li>Every time we do a test/get another chance we require to hit a lower overall significance threshold.</li>
<li>Pro: allow a more flexible approach based on the specific circumstances of a study.</li>
<li>Cons:<ul>
<li>Can we actually count the tests/chances in an accurate and trustworthy way?</li>
<li>Proper adjustment isn&apos;t always clear.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Test Important Hypotheses, not Cute Hypotheses</strong>: <ul>
<li>If we read a study that would have never been published had they found a null result, we would be more worried about multiple testing and selective reporting.</li>
<li>If researchers test questions for which we care about the answer, even if it is null, then a lot of these problems go away.</li>
<li>Most important questions fall into the latter category, whereas a lot of cute and fun questions fall into the former category.</li>
</ul>
</li>
<li><strong>Be Skeptical</strong>:<ul>
<li>Individual studies can be flawed, and we should be skeptical of the <strong>newest, cutest</strong> scientific result.</li>
<li>Our hope is that even though individual studies are flawed, scientific literatures can be valuable nonetheless after we have done lots of theory, testing, replication, and meta-analysis.</li>
</ul>
</li>
<li><strong>Reprise on p-values</strong>:<ul>
<li>p-values and hypothesis testing are useful tools, but they can be abused.</li>
<li>p-values solve an important problem, so they should be used when appropriate.</li>
<li>But they are not the ultimate method for assessing the credibility of an empirical result. </li>
</ul>
</li>
</ul>
</li>
</ul>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="Module11.html" class="navigation navigation-prev " aria-label="Previous page: Module 11 Bayesian Inference and Base Rates">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="Module13.html" class="navigation navigation-next " aria-label="Next page: Module 13 Reversion to the Mean">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Module 12 Multiple Testing, Reporting Bias, and Misinterpreting Outliers","level":"1.1.11","depth":2,"next":{"title":"Module 13 Reversion to the Mean","level":"1.1.12","depth":2,"path":"Module13.md","ref":"Module13.md","articles":[]},"previous":{"title":"Module 11 Bayesian Inference and Base Rates","level":"1.1.10","depth":2,"path":"Module11.md","ref":"Module11.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":["katex"],"pluginsConfig":{"katex":{},"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"Module12.md","mtime":"2023-11-27T18:40:55.555Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2023-12-04T21:24:03.372Z"},"basePath":".","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="gitbook/gitbook.js"></script>
    <script src="gitbook/theme.js"></script>
    
        
        <script src="gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

